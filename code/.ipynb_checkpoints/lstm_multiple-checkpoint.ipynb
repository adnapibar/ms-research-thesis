{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 960 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.models import Sequential\n",
    "import plotly\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set a random seed to reproduce the results\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Load the volume data\n",
    "volume_data = pd.read_csv('../data/volume_data.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_hfs = pd.read_csv('../data/hf_list.csv')\n",
    "\n",
    "used_hfs = [16911, 16912, 16913, 278, 10528, 16515, 14479, 16551, 6297, 16537, 16538]\n",
    "\n",
    "def find_index_hf(hf_no):\n",
    "    return all_hfs[all_hfs['HF'] == hf_no].index.tolist()[0]\n",
    "\n",
    "hfs = [find_index_hf(hf_no) for hf_no in used_hfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxs = []\n",
    "mins = []\n",
    "means = []\n",
    "stds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_traffic_data(sequence_length=50, horizon=15):\n",
    "    global maxs\n",
    "    global mins\n",
    "    global means\n",
    "    global stds\n",
    "    maxs = []\n",
    "    mins = []\n",
    "    means = []\n",
    "    stds = []\n",
    "     # for 30 minutes aggregate divide by 2\n",
    "    sample_size = int(volume_data.shape[0] * (15/horizon))\n",
    "    result = []\n",
    "    # scale data\n",
    "    # Create data\n",
    "    for j in hfs:\n",
    "        road_vol = volume_data[j]\n",
    "        road_vol = road_vol.replace(0, np.nan) \n",
    "        road_vol = road_vol.interpolate().values \n",
    "        \n",
    "        if horizon == 30:\n",
    "            road_vol = road_vol[0::2] + road_vol[1::2] \n",
    "        elif horizon == 45:\n",
    "            road_vol = road_vol[0::3] + road_vol[1::3] + road_vol[2::3]\n",
    "        # for 30 minutes aggregate\n",
    "        # road_vol = road_vol[0::2] + road_vol[1::2]\n",
    "        \n",
    "        mean_t = road_vol.mean()\n",
    "        max_t = road_vol.max()\n",
    "        min_t = road_vol.min()\n",
    "        std_t = np.std(road_vol)\n",
    "        \n",
    "        mins.append(min_t)\n",
    "        maxs.append(max_t)\n",
    "        means.append(mean_t)\n",
    "        stds.append(std_t)\n",
    "        \n",
    "        road_vol = (road_vol - mean_t) / std_t\n",
    "        temp = []\n",
    "        for i in range(0, sample_size - sequence_length):\n",
    "            temp.append(road_vol[i: i + sequence_length])\n",
    "        result.append(temp)\n",
    "\n",
    "    result = np.dstack(result)\n",
    "    #row = round(0.9 * result.shape[0])\n",
    "    row = result.shape[0] - 5280\n",
    "    train = result[:row, :, :]\n",
    "    np.random.shuffle(train)\n",
    "    X_train = train[:, :-1, :]\n",
    "    y_train = train[:, -1, :]\n",
    "    X_test = result[row:, :-1, :]\n",
    "    y_test = result[row:, -1, :]\n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    mdl = Sequential()\n",
    "    io_dim = len(hfs)\n",
    "    # a network with len(hfs)-dimensional input,\n",
    "    # 3 hidden layers of sizes 100, 200, 200\n",
    "    # and eventually a len(hfs)-dimensional output layer\n",
    "    layers = [io_dim, 200, 200, io_dim]\n",
    "\n",
    "    # We also add 20% Dropout in this layer.\n",
    "    mdl.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    mdl.add(Dropout(0.2))\n",
    "    \n",
    "    # 3rd hidden layer\n",
    "    mdl.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    mdl.add(Dropout(0.2))\n",
    "\n",
    "    # last layer we use is a Dense layer ( = feedforward).\n",
    "    # Since we are doing a regression, its activation is linear\n",
    "    mdl.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    mdl.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    mdl.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_rnn_model():\n",
    "    mdl = Sequential()\n",
    "    io_dim = len(hfs)\n",
    "    # a network with 1-dimensional input,\n",
    "    # two hidden layers of sizes 100 and 100\n",
    "    # and eventually a 1-dimensional output layer\n",
    "    layers = [io_dim, 200, 200, io_dim]\n",
    "\n",
    "    # We also add 10% Dropout in this layer.\n",
    "    mdl.add(SimpleRNN(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    mdl.add(Dropout(0.1))\n",
    "\n",
    "    # 3rd hidden layer\n",
    "    mdl.add(SimpleRNN(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    mdl.add(Dropout(0.2))\n",
    "    \n",
    "    # last layer we use is a Dense layer ( = feedforward).\n",
    "    # Since we are doing a regression, its activation is linear\n",
    "    mdl.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    mdl.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    mdl.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gru_model():\n",
    "    mdl = Sequential()\n",
    "    io_dim = len(hfs)\n",
    "    # a network with 1-dimensional input,\n",
    "    # two hidden layers of sizes 50 and 100\n",
    "    # and eventually a 1-dimensional output layer\n",
    "    layers = [io_dim, 200, 200, io_dim]\n",
    "\n",
    "    # We also add 20% Dropout in this layer.\n",
    "    mdl.add(GRU(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    mdl.add(Dropout(0.2))\n",
    "\n",
    "    # 2nd hidden layer\n",
    "    mdl.add(GRU(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    mdl.add(Dropout(0.2))\n",
    "    \n",
    "    # last layer we use is a Dense layer ( = feedforward).\n",
    "    # Since we are doing a regression, its activation is linear\n",
    "    mdl.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    mdl.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    mdl.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_network(data, mdl_type):\n",
    "    global_start_time = time.time()\n",
    "    epochs = 20\n",
    "\n",
    "    X_train, y_train, X_test, y_test = data\n",
    "\n",
    "    print('\\nData Loaded. Compiling...\\n')\n",
    "\n",
    "    if mdl_type == 'rnn':\n",
    "        mdl = simple_rnn_model()\n",
    "    elif mdl_type == 'gru':\n",
    "        mdl = gru_model()\n",
    "    elif mdl_type == 'lstm':\n",
    "        mdl = lstm_model()\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        mdl.fit(X_train, y_train, batch_size=512,\n",
    "                nb_epoch=epochs, validation_split=0.05)\n",
    "        predicted_trffic = mdl.predict(X_test)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Training duration (s) : ', time.time() - global_start_time)\n",
    "        return mdl, y_test, 0\n",
    "\n",
    "    print('Training duration (s) : ', time.time() - global_start_time)\n",
    "\n",
    "    return mdl, y_test, predicted_trffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_predictions(y_test, predicted, horizon):\n",
    "    y_test_tp = np.transpose(y_test)\n",
    "    pred_tp = np.transpose(predicted)\n",
    "   \n",
    "    i = 2 #hf no 16913\n",
    "    actual = (y_test_tp[i] * stds[i]) + means[i]\n",
    "    predictions = (pred_tp[i] * stds[i]) + means[i]\n",
    "   \n",
    "    actual = actual[:2880]\n",
    "    predictions = predictions[:2880]\n",
    "    \n",
    "    t = pd.date_range('6/1/2012', freq=(str(horizon)+'Min'), periods=(30*96*15)/horizon)\n",
    "    trace0 = go.Scatter(\n",
    "        x = t,\n",
    "        y = actual,\n",
    "        name = 'Actual')\n",
    "    trace1 = go.Scatter(\n",
    "        x = t,\n",
    "        y = predictions,\n",
    "        name = 'Predicted')\n",
    "    data = [trace0, trace1]\n",
    "\n",
    "    layout = dict(xaxis = dict(title = 'Time'),\n",
    "                  yaxis = dict(title = 'Volume'),\n",
    "                  width = 600, height = 450)\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    plotly.offline.plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def print_scores(y_test, predicted):\n",
    "    y_test_tp = np.transpose(y_test)\n",
    "    pred_tp = np.transpose(predicted)\n",
    "    for i in range(0, len(used_hfs)):\n",
    "        mae = []\n",
    "        mse = []\n",
    "        mape = []\n",
    "        print(\"Score for location -- \", used_hfs[i])\n",
    "        actual = y_test_tp[i]\n",
    "        predictions = pred_tp[i]\n",
    "\n",
    "        actual = actual[:2880]\n",
    "        predictions = predictions[:2880]\n",
    "\n",
    "        actual = (actual * stds[i]) + means[i]\n",
    "        predictions = (predictions * stds[i]) + means[i]\n",
    "\n",
    "        mae.append(mean_absolute_error(actual, predictions))\n",
    "        mse.append(mean_squared_error(actual, predictions))\n",
    "        mape.append(mean_absolute_percentage_error(actual, predictions))\n",
    "        print(\"MAE=\", np.array(mae).mean())\n",
    "        print(\"RMSE=\", math.sqrt(np.array(mse).mean()))\n",
    "        print(\"MAPE=\", np.array(mape).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = train_test_traffic_data(50,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Loaded. Compiling...\n",
      "\n",
      "Compilation Time :  0.14113426208496094\n",
      "Train on 180346 samples, validate on 9492 samples\n",
      "Epoch 1/20\n",
      "180346/180346 [==============================] - 128s - loss: 0.0994 - val_loss: 0.0582\n",
      "Epoch 2/20\n",
      "180346/180346 [==============================] - 129s - loss: 0.0668 - val_loss: 0.0541\n",
      "Epoch 3/20\n",
      "180346/180346 [==============================] - 129s - loss: 0.0628 - val_loss: 0.0523\n",
      "Epoch 4/20\n",
      "180346/180346 [==============================] - 130s - loss: 0.0607 - val_loss: 0.0510\n",
      "Epoch 5/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0594 - val_loss: 0.0506\n",
      "Epoch 6/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0585 - val_loss: 0.0498\n",
      "Epoch 7/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0576 - val_loss: 0.0497\n",
      "Epoch 8/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0570 - val_loss: 0.0493\n",
      "Epoch 9/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0565 - val_loss: 0.0484\n",
      "Epoch 10/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0562 - val_loss: 0.0491\n",
      "Epoch 11/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0557 - val_loss: 0.0480\n",
      "Epoch 12/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0553 - val_loss: 0.0478\n",
      "Epoch 13/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0550 - val_loss: 0.0478\n",
      "Epoch 14/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0547 - val_loss: 0.0479\n",
      "Epoch 15/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0545 - val_loss: 0.0476\n",
      "Epoch 16/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0543 - val_loss: 0.0472\n",
      "Epoch 17/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0540 - val_loss: 0.0473\n",
      "Epoch 18/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0537 - val_loss: 0.0474\n",
      "Epoch 19/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0536 - val_loss: 0.0466\n",
      "Epoch 20/20\n",
      "180346/180346 [==============================] - 131s - loss: 0.0534 - val_loss: 0.0472\n",
      "Training duration (s) :  2643.5376975536346\n"
     ]
    }
   ],
   "source": [
    "#Using ADAM\n",
    "model, y_test, predicted = run_network(data, 'lstm')\n",
    "plot_predictions(y_test, predicted, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for location --  16911\n",
      "MAE= 19.8635291981\n",
      "RMSE= 27.845087913657473\n",
      "MAPE= 20.8806170447\n",
      "Score for location --  16912\n",
      "MAE= 33.8460844535\n",
      "RMSE= 46.61691032372916\n",
      "MAPE= 13.1943939923\n",
      "Score for location --  16913\n",
      "MAE= 16.5449778342\n",
      "RMSE= 22.981055954232218\n",
      "MAPE= 11.2777049074\n",
      "Score for location --  278\n",
      "MAE= 21.7565968696\n",
      "RMSE= 31.04059021607899\n",
      "MAPE= 10.203335787\n",
      "Score for location --  10528\n",
      "MAE= 47.3382146236\n",
      "RMSE= 72.46946135723091\n",
      "MAPE= 8.27286663525\n",
      "Score for location --  16515\n",
      "MAE= 13.6881839478\n",
      "RMSE= 18.4455207137336\n",
      "MAPE= 11.7584917301\n",
      "Score for location --  14479\n",
      "MAE= 9.82515936151\n",
      "RMSE= 14.047833942586331\n",
      "MAPE= 13.0005835189\n",
      "Score for location --  16551\n",
      "MAE= 10.0674105055\n",
      "RMSE= 14.698022859261796\n",
      "MAPE= 23.4996035994\n",
      "Score for location --  6297\n",
      "MAE= 21.3259761773\n",
      "RMSE= 28.48820160649142\n",
      "MAPE= 21.9632772425\n",
      "Score for location --  16537\n",
      "MAE= 19.8614294318\n",
      "RMSE= 28.221168089832123\n",
      "MAPE= 18.6496325141\n"
     ]
    }
   ],
   "source": [
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for location --  16911\n",
      "MAE= 19.8635291981\n",
      "RMSE= 27.845087913657473\n",
      "MAPE= 20.8806170447\n",
      "Score for location --  16912\n",
      "MAE= 33.8460844535\n",
      "RMSE= 46.61691032372916\n",
      "MAPE= 13.1943939923\n",
      "Score for location --  16913\n",
      "MAE= 16.5449778342\n",
      "RMSE= 22.981055954232218\n",
      "MAPE= 11.2777049074\n",
      "Score for location --  278\n",
      "MAE= 21.7565968696\n",
      "RMSE= 31.04059021607899\n",
      "MAPE= 10.203335787\n",
      "Score for location --  10528\n",
      "MAE= 47.3382146236\n",
      "RMSE= 72.46946135723091\n",
      "MAPE= 8.27286663525\n",
      "Score for location --  16515\n",
      "MAE= 13.6881839478\n",
      "RMSE= 18.4455207137336\n",
      "MAPE= 11.7584917301\n",
      "Score for location --  14479\n",
      "MAE= 9.82515936151\n",
      "RMSE= 14.047833942586331\n",
      "MAPE= 13.0005835189\n",
      "Score for location --  16551\n",
      "MAE= 10.0674105055\n",
      "RMSE= 14.698022859261796\n",
      "MAPE= 23.4996035994\n",
      "Score for location --  6297\n",
      "MAE= 21.3259761773\n",
      "RMSE= 28.48820160649142\n",
      "MAPE= 21.9632772425\n",
      "Score for location --  16537\n",
      "MAE= 19.8614294318\n",
      "RMSE= 28.221168089832123\n",
      "MAPE= 18.6496325141\n"
     ]
    }
   ],
   "source": [
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='../latex-thesis/Figures/lstm_multi_variate.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Loaded. Compiling...\n",
      "\n",
      "Compilation Time :  0.08727669715881348\n",
      "Train on 180346 samples, validate on 9492 samples\n",
      "Epoch 1/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.1787 - val_loss: 0.0634\n",
      "Epoch 2/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0810 - val_loss: 0.0586\n",
      "Epoch 3/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0711 - val_loss: 0.0571\n",
      "Epoch 4/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0676 - val_loss: 0.0561\n",
      "Epoch 5/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0659 - val_loss: 0.0559\n",
      "Epoch 6/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0647 - val_loss: 0.0554\n",
      "Epoch 7/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0640 - val_loss: 0.0560\n",
      "Epoch 8/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0634 - val_loss: 0.0542\n",
      "Epoch 9/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0629 - val_loss: 0.0542\n",
      "Epoch 10/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0625 - val_loss: 0.0542\n",
      "Epoch 11/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0622 - val_loss: 0.0546\n",
      "Epoch 12/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0620 - val_loss: 0.0548\n",
      "Epoch 13/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0619 - val_loss: 0.0538\n",
      "Epoch 14/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0615 - val_loss: 0.0538\n",
      "Epoch 15/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0614 - val_loss: 0.0539\n",
      "Epoch 16/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0612 - val_loss: 0.0544\n",
      "Epoch 17/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0609 - val_loss: 0.0547\n",
      "Epoch 18/20\n",
      "180346/180346 [==============================] - 29s - loss: 0.0609 - val_loss: 0.0525\n",
      "Epoch 19/20\n",
      "131072/180346 [====================>.........] - ETA: 8s - loss: 0.0607Training duration (s) :  567.8254656791687\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-dfe8e7d2593c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rnn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-c7db94bc32cd>\u001b[0m in \u001b[0;36mplot_predictions\u001b[1;34m(y_test, predicted, horizon)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;31m#hf no 16913\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mactual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test_tp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_tp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mactual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2880\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "model, y_test, predicted = run_network(data, 'rnn')\n",
    "plot_predictions(y_test, predicted, 15)\n",
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, y_test, predicted = run_network(data, 'gru')\n",
    "plot_predictions(y_test, predicted, 15)\n",
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = train_test_traffic_data(50,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, y_test, predicted = run_network(data, 'lstm')\n",
    "plot_predictions(y_test, predicted, 30)\n",
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, y_test, predicted = run_network(data, 'rnn')\n",
    "plot_predictions(y_test, predicted, 30)\n",
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, y_test, predicted = run_network(data, 'gru')\n",
    "plot_predictions(y_test, predicted, 30)\n",
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = train_test_traffic_data(50,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, y_test, predicted = run_network(data,'lstm')\n",
    "plot_predictions(y_test, predicted, 45)\n",
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, y_test, predicted = run_network(data, 'rnn')\n",
    "plot_predictions(y_test, predicted, 30)\n",
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, y_test, predicted = run_network(data, 'gru')\n",
    "plot_predictions(y_test, predicted, 30)\n",
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
