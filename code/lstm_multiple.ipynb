{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 960 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set a random seed to reproduce the results\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Load the volume data\n",
    "volume_data = pd.read_csv('../data/volume_data.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_hfs = pd.read_csv('../data/hf_list.csv')\n",
    "\n",
    "used_hfs = [6336, 16572, 3393, 13632, 3592, 13829, 268, 6278, 10522, 16515, 16517,\n",
    "            5539, 9615, 15773, 19854, 6782, 17022, 9424, 19659]\n",
    "\n",
    "def find_index_hf(hf_no):\n",
    "    return all_hfs[all_hfs['GID'] == hf_no].index.tolist()[0]\n",
    "\n",
    "hfs = [find_index_hf(hf_no) for hf_no in used_hfs]\n",
    "\n",
    "means = []\n",
    "maxs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return a training and test data for a site.\n",
    "def train_test_traffic_data(sequence_length=50):\n",
    "    sample_size = volume_data.shape[0]\n",
    "    result = []\n",
    "    # scale data\n",
    "    # Create data\n",
    "    for j in hfs:\n",
    "        road_vol = volume_data[j]\n",
    "        road_vol = road_vol.replace(0, int(road_vol.mean())).values\n",
    "        means.append(road_vol.mean())\n",
    "        maxs.append(road_vol.max())\n",
    "        road_vol = (road_vol - road_vol.mean())/road_vol.max()\n",
    "        temp = []\n",
    "        for i in range(0, sample_size - sequence_length):\n",
    "            temp.append(road_vol[i: i + sequence_length])\n",
    "        result.append(temp)\n",
    "\n",
    "    result = np.dstack(result)\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:row, :, :]\n",
    "    np.random.shuffle(train)\n",
    "    X_train = train[:, :-1, :]\n",
    "    y_train = train[:, -1, :]\n",
    "    X_test = result[row:, :-1, :]\n",
    "    y_test = result[row:, -1, :]\n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    mdl = Sequential()\n",
    "    io_dim = len(hfs)\n",
    "    # a network with 1-dimensional input,\n",
    "    # two hidden layers of sizes 50, 100 and 100\n",
    "    # and eventually a 1-dimensional output layer\n",
    "    layers = [io_dim, 100, 200, 200, io_dim]\n",
    "\n",
    "    # We also add 20% Dropout in this layer.\n",
    "    mdl.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    mdl.add(Dropout(0.2))\n",
    "    \n",
    "    # 2nd hidden layer\n",
    "    mdl.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=True))\n",
    "    mdl.add(Dropout(0.2))\n",
    "\n",
    "    # 3rd hidden layer\n",
    "    mdl.add(LSTM(\n",
    "        layers[3],\n",
    "        return_sequences=False))\n",
    "    mdl.add(Dropout(0.2))\n",
    "\n",
    "    # last layer we use is a Dense layer ( = feedforward).\n",
    "    # Since we are doing a regression, its activation is linear\n",
    "    mdl.add(Dense(\n",
    "        output_dim=layers[4]))\n",
    "    mdl.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    mdl.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_network(mdl=None, data=None):\n",
    "    global_start_time = time.time()\n",
    "    epochs = 20\n",
    "    sequence_length = 50\n",
    "\n",
    "    if data is None:\n",
    "        print('Loading data... ')\n",
    "        X_train, y_train, X_test, y_test = train_test_traffic_data(sequence_length)\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = data\n",
    "\n",
    "    print('\\nData Loaded. Compiling...\\n')\n",
    "\n",
    "    if mdl is None:\n",
    "        mdl = build_model()\n",
    "\n",
    "    try:\n",
    "        mdl.fit(X_train, y_train, batch_size=512,\n",
    "                nb_epoch=epochs, validation_split=0.05)\n",
    "        predicted_trffic = mdl.predict(X_test)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Training duration (s) : ', time.time() - global_start_time)\n",
    "        return mdl, y_test, 0\n",
    "\n",
    "    print('Training duration (s) : ', time.time() - global_start_time)\n",
    "\n",
    "    return mdl, y_test, predicted_trffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = train_test_traffic_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Loaded. Compiling...\n",
      "\n",
      "Compilation Time :  0.21184515953063965\n",
      "Train on 166782 samples, validate on 8779 samples\n",
      "Epoch 1/20\n",
      "166782/166782 [==============================] - 310s - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 2/20\n",
      "166782/166782 [==============================] - 311s - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 3/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 5/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 6/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 7/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 8/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 9/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 10/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 11/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 12/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 13/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 14/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 15/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 16/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 17/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 18/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 19/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 20/20\n",
      "166782/166782 [==============================] - 313s - loss: 0.0030 - val_loss: 0.0024\n",
      "Training duration (s) :  6344.173142194748\n"
     ]
    }
   ],
   "source": [
    "model, y_test, predicted = run_network(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_predictions(y_test, predicted):\n",
    "    x = np.arange(400)\n",
    "    y_test_tp = np.transpose(y_test)\n",
    "    pred_tp = np.transpose(predicted)\n",
    "    i = 13 #hf no 15773\n",
    "    actual = y_test_tp[i][:400]\n",
    "    predictions = pred_tp[i][:400]\n",
    "    actual = (actual * maxs[i]) + means[i]\n",
    "    predictions = (predictions * maxs[i]) + means[i]\n",
    "    plt.plot(x,actual, label='Actual')\n",
    "    plt.plot(x,predictions, label='Predicted')\n",
    "    plt.legend(loc=2)\n",
    "    plt.savefig('../latex-thesis/Figures/lstm-multi.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "def print_scores(y_test, predicted):\n",
    "    y_test_tp = np.transpose(y_test)\n",
    "    pred_tp = np.transpose(predicted)\n",
    "    mae = []\n",
    "    mse = []\n",
    "    mape = []\n",
    "    #for i in range(len(hfs)):\n",
    "    i=13\n",
    "    actual = y_test_tp[i]\n",
    "    predictions = pred_tp[i]\n",
    "    actual = (actual * maxs[i]) + means[i]\n",
    "    predictions = (predictions * maxs[i]) + means[i]\n",
    "    mae.append(mean_absolute_error(actual, predictions))\n",
    "    mse.append(mean_squared_error(actual, predictions))\n",
    "    mape.append(mean_absolute_percentage_error(actual, predictions))\n",
    "    print(\"MAE=\", np.array(mae).mean())\n",
    "    print(\"MSE=\", np.array(mse).mean())\n",
    "    print(\"MAPE=\", np.array(mape).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_predictions(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE= 15.1392187394\n",
      "MSE= 479.762545996\n",
      "MAPE= 17.7729902716\n"
     ]
    }
   ],
   "source": [
    "print_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
