% Chapter 4

\chapter{A Deep Recurrent Network Model for Traffic Flow Prediction} % Main chapter title

\label{Chapter4} % For referencing the chapter elsewhere, use \ref{Chapter4}

% This is for the header on each page - perhaps a shortened title
\lhead{Chapter 4. \emph{A Deep Recurrent Network Model for Traffic Flow Prediction}}

% Quotation
{``I am a brain, Watson. The rest of me is a mere appendix."}
\begin{flushright}
Arthur Conan Doyle, \textit{The Adventure of the Mazarin Stone} (1921)
\end{flushright}

%---------------------------------------------------------------------------------------------------
%	CONTENT
%---------------------------------------------------------------------------------------------------

\section{Introduction}
Today we live in a world where almost every interaction of ours with the external world uses some
form of computing. Computers have become an inseparable part of human lives. In the earlier days
when computers were built, people began to ponder whether they could achieve human level
of intelligence. Even though at that point the answers seemed optimistic, it has taken quite
some time and understanding on our part to make significant achievements in the field of
artificial intelligence. One of the approaches was to use knowldge base systems, where computers
reason about real world concepts, that were defined in hard-coded formal langauges, using logical
inference rules. These systems led to little success. The difficulties faced in the knwoledge
based appproach made us built computers to learn automatically from data, an approach we know as
machine learning. A large number of real world problems could eaily be tackled using machine
leraning. However for the machine learning algorithms to perorm well they need to be provided
with proper representaion of data. For example <TODO - an exmple of representaion>

Finding a proper representation from data is a challenge and sometimes become very difficult.

<TODO - Deep learning>

\section{Recurrent neural networks}

\subsection{LSTM Networks}
In previous section we learn that using a recurrent neural networks we can store information in
form of activations in the feedback connnections.
